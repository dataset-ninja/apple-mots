The **Apple MOTS: Multiple Object Tracking and Segmentation in an Apple Orchard Field** dataset comprises temporally synchronized images and labels of apples, captured using UAVs (Unmanned Aerial Vehicles) and a wearable sensor in an orchard. It includes a total of 86,000 manually annotated apple instances and 1,700 frames annotated following the MOTS (Multi-object Tracking and Segmentation) style. Sequences 0 to 5 are allocated for training, while sequences 6 to 8 are designated for testing and validation. Sequences 10 to 12 represent the testing datasets, which feature overlays for "ignore regions."
